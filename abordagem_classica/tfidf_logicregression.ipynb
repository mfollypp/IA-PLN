{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e7355a",
   "metadata": {},
   "source": [
    "O primeiro passo para nosso projeto é decidir quais técnicas iremos usar para o nosso metodo classico de classificação. Optamos por usar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31e955",
   "metadata": {},
   "source": [
    "Começamos por ler nosso csv de treino e teste e separar o texto e as emoções, criaremos também a coluna para neutro, para quando nenhuma das emoções for identificada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a00ff091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"treino/ptbr.csv\")\n",
    "teste = pd.read_csv(\"teste/ptbr.csv\")\n",
    "\n",
    "\n",
    "data[\"neutral\"] = (data[[\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].sum(axis=1) == 0).astype(int)\n",
    "teste[\"neutral\"] = (teste[[\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].sum(axis=1) == 0).astype(int)\n",
    "\n",
    "texto = data[\"text\"]\n",
    "emocao = data[[\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]]\n",
    "\n",
    "texto_teste = teste[\"text\"]\n",
    "emocao_teste = teste[[\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"neutral\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf14883",
   "metadata": {},
   "source": [
    "Iremos transformar o texto em vetores usando o sklearn, e depois o Sklearn fará a Regressão Lógica, após isso faremos o fit para o treino e por fim a predição do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aea31fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "features = FeatureUnion([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfidf', TfidfVectorizer())\n",
    "])\n",
    "\n",
    "ordem = Pipeline([\n",
    "    ('features', features),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(class_weight='balanced')))\n",
    "])\n",
    "\n",
    "ordem_sem_bal = Pipeline([\n",
    "    ('features', features),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "])\n",
    "\n",
    "ordem.fit(texto, emocao)\n",
    "ordem_sem_bal.fit(texto,emocao)\n",
    "\n",
    "probas = ordem.predict_proba(texto_teste)\n",
    "\n",
    "threshold = 0.3141592653589793\n",
    "predi = (probas >= threshold).astype(int)\n",
    "predi_sem_bal = ordem_sem_bal.predict(texto_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c41dc",
   "metadata": {},
   "source": [
    "Para comparação estamos trabalhando com 2 modelos, um onde apenas aplicamos o que foi aprendido com o conjunto de treino na nossa base de testes, e outro onde aplicamos técnicas para possivelmente melhorar nossos resultados, essas técnicas são, o blaceamento de classes minoritárias, dando mais peso a elas, e um threshold diferente do padrão, aqui foi escolhido o valor de pi como um valor aleátorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d23f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.48      0.75      0.58       699\n",
      "     disgust       0.18      0.24      0.21        71\n",
      "        fear       0.20      0.24      0.22       139\n",
      "         joy       0.47      0.72      0.57       555\n",
      "     sadness       0.35      0.59      0.44       343\n",
      "    surprise       0.13      0.24      0.17       157\n",
      "     neutral       0.41      0.74      0.52       616\n",
      "\n",
      "   micro avg       0.40      0.65      0.49      2580\n",
      "   macro avg       0.32      0.50      0.39      2580\n",
      "weighted avg       0.40      0.65      0.49      2580\n",
      " samples avg       0.44      0.67      0.50      2580\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.43      0.51       699\n",
      "     disgust       0.00      0.00      0.00        71\n",
      "        fear       0.60      0.04      0.08       139\n",
      "         joy       0.76      0.41      0.53       555\n",
      "     sadness       0.60      0.25      0.35       343\n",
      "    surprise       0.20      0.01      0.02       157\n",
      "     neutral       0.50      0.33      0.40       616\n",
      "\n",
      "   micro avg       0.62      0.32      0.42      2580\n",
      "   macro avg       0.47      0.21      0.27      2580\n",
      "weighted avg       0.58      0.32      0.40      2580\n",
      " samples avg       0.35      0.33      0.34      2580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theod\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\theod\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(emocao_teste, predi, target_names=emocao_teste.columns))\n",
    "print(classification_report(emocao_teste, predi_sem_bal, target_names=emocao_teste.columns))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
